# 今日todolist:
1. 继续尝试使用grpo优化
2. 阅读扩散模型文献 and ORC文献

(ps: 想吃木桶饭了)

做到一半，愈发感知到数据处理的重要性。有没有什么办法，我可以更加智能的从新闻中提取事件，无需每个数据集去对齐？

思考...
其实我在做的任务就是将数值和文本进行对齐，现在存在的问题是: 目前是在文本空间进行对齐，但是这个对齐空间构造的并不是非常得合理，我需要复杂预处理令其合理化。复杂的预处理会不可避免的影响最终的合理程度。
我能不能绕开这一步骤？不需要每个数据集进行预处理的校准，最好是直接喂进来数值和文本，可以模型自我进行校准。让模型自我迭代处理...好像有些困难。可以使用agent吗？环境是对应的流程是数据的处理和参数，得分是最终的结果。
看起来值得一试，等我把三个数据集跑通就去试试agent自我调优。

不想这些有的没的了。之前在grpo微调时发现，模型会通过一些很奇怪的方式[解读]数值token，我猜测可能是由于直接通过sft微调encoder需要将大量信息压缩进数值token，导致LLM后解码失败。

所以第一步微调时将推理步骤去掉也是一个值得尝试的方向，减少需要压缩的中间信息，直接关注最重要的结果。
