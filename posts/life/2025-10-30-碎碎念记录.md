# 近期汇总
最近的时间在用来扩展数据集，目前共完成了8份采样频率为月和周的 数据集的 事件提取预处理。

事实上，在做这件事前，我没有想到会这么复杂。举例来说 在失业率数据集中 客体有90%都是Unemployment Rate本身。

我需要一步步去调整候选词表来供LLM选择，希望尽量分布平衡方便后续训练，但是因为数据集本身就带有偏置，所以每次修改prompt过数据就像开盲盒一样等待，且大概率效果不会很好。

但是一步步更新候选词表实在太过折磨，我想到了另一个办法。我调用agent替代我自动读取每一行的新闻并总结它认为合理的 主体 行为 客体，之后我选择每个slot中topk的候选词。

这样效率高了很多，之后我再对词表进行微调。举例来说其中农业数据集的候选词数目明显高于topk，我担心再取topk会难以覆盖尽量多的事件，所以交由gpt5进行候选词的汇总，把相近的候选词汇总成一个较大的类。

目前初步来看，我认为比较满意的数据集有 灾害数据集 和 交通数据集，他们的分布相对来说平衡一些。不过他们的采样频率都是月度(事实上9个数据集中有6个月度，2个周度，1个日度),所以后面的框架可能需要一定的修改。

理想情况是有3个及以上的数据集。因为横着列表格的话，3个数据集 * 2个指标 + 一列行头，共7列可以显得比较满。
# 后续计划
后续的话，针对之前发现在某些数据集上合成数值会出现负值的情况。我计划在数值外加上log避免负值，同时调整超参数。

假如目前这个合成数据完全跑通且证明有效，就先把文章完善好(实验，画图)。

接着再尝试一些使用基于agent的数据合成方法。
